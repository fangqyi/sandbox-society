

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Welcome to the Platform! &mdash; Neural MMO 1.3 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Foreword" href="devguide.html" />
    <link rel="prev" title="Neural MMO v1.4" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Neural MMO
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Guide:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#"> Welcome to the Platform!</a></li>
<li class="toctree-l1"><a class="reference internal" href="#icon-overview"> Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#research">Research</a></li>
<li class="toctree-l2"><a class="reference internal" href="#engineering">Engineering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#icon-quickstart"> Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="#icon-publications"> Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="#icon-demos"> Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="#icon-patch-notes-version-history"> Patch Notes + Version History</a></li>
<li class="toctree-l1"><a class="reference internal" href="#icon-rendering-and-overlays"> Rendering and Overlays</a></li>
<li class="toctree-l1"><a class="reference internal" href="#icon-tutorials"> Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#training-from-scratch">Training from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-io-api">The IO API</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#icon-ideology"> Ideology</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#icon-failure-modes"> Failure Modes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#icon-authorship-license-disclaimer"> Authorship, License, Disclaimer</a></li>
<li class="toctree-l1"><a class="reference internal" href="#icon-assets"> Assets</a></li>
<li class="toctree-l1"><a class="reference internal" href="#ags-namesake"> Namesake</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Guide:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="devguide.html"> Foreword</a></li>
<li class="toctree-l1"><a class="reference internal" href="devguide.html#ags-before-you-start"> Before You Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="devguide.html#ags-tech-stack"> Tech Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="devguide.html#ags-versioning"> Versioning</a></li>
<li class="toctree-l1"><a class="reference internal" href="devguide.html#ags-style"> Style</a></li>
</ul>
<p class="caption"><span class="caption-text">Documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="autodoc/api.html"> User API</a></li>
<li class="toctree-l1"><a class="reference internal" href="autodoc/api.html#ags-developer-api"> Developer API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Neural MMO</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li> Welcome to the Platform!</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/overview.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <p><img alt="env" src="_images/v1-4_splash.png" /></p>
<div class="section" id="icon-welcome-to-the-platform">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Welcome to the Platform!<a class="headerlink" href="#icon-welcome-to-the-platform" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://youtu.be/DkHopV1RSxw">[Demo Video]</a> | <a class="reference external" href="https://github.com/jsuarez5341/neural-mmo">[Github]</a> | <a class="reference external" href="https://discord.gg/BkMmFUC">[Discord]</a> | <a class="reference external" href="https://twitter.com/jsuarez5341">[Twitter]</a></p>
<p>Progress in multiagent intelligence research is fundamentally limited by the complexity of environments available for study. Neural MMO is a massively multiagent AI research environment inspired by Massively Multiplayer Online (MMO) role playing games – self-contained worlds featuring thousands of agents per persistent macrocosm, diverse skilling systems, local and global economies, complex emergent social structures, and ad-hoc high-stakes single and team based conflict.  Our goal is not to simulate the near-infinite physical processes of life on Earth but instead to construct an efficient facsimile that incentivizes the emergence of high-level social and general artificial intelligence. To this end, we consider MMOs the best proxy for the real world among human games.</p>
<p><strong>Getting Started:</strong> Neural MMO extends the OpenAI Gym API to support additional environment complexity: persistence, large/variable agent populations, and hierarchical observation/action spaces. The quickest way to dive in is:</p>
<p><strong>1:</strong> Work through the <a class="reference external" href="https://jsuarez5341.github.io/neural-mmo/build/html/overview.html#ags-quickstart">[Quickstart Guide]</a> and familiarize yourself with the <a class="reference external" href="https://jsuarez5341.github.io/neural-mmo/build/html/autodoc/forge.blade.core.realm.html">[Realm API]</a></p>
<p><strong>2:</strong> Join our <a class="reference external" href="https://discord.gg/BkMmFUC">[Discord]</a> community for help and discussion. <strong>This is the best way to contact me</strong></p>
<p><strong>3:</strong> Develop your own fork and contribute your features to the platform. Neural MMO is fully open-source – to succeed long-term, we will need the help of talented researchers, software engineers, game designers, and technical artists. I actively review issues and pull requests.</p>
</div>
<div class="section" id="icon-overview">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Overview<a class="headerlink" href="#icon-overview" title="Permalink to this headline">¶</a></h1>
<img alt="_images/overview.svg" src="_images/overview.svg" /><p><strong>Agents that scale to the complexity of the real world</strong> is one statement of artificial general intelligence. We propose a Dual Subproblem reformulation that cleanly segments this objective into concrete and approachable research and engineering tasks. The project is divided into two research and two engineering modules along these lines – see <a class="reference external" href="https://jsuarez5341.github.io/neural-mmo/build/html/overview.html#ags-ideology">[Ideology]</a> if you find this sort of macro view interesting.</p>
<div class="section" id="research">
<h2>Research<a class="headerlink" href="#research" title="Permalink to this headline">¶</a></h2>
<p><strong>Agents that scale to the complexity of their environment</strong></p>
<p><img alt="water" src="_images/water.png" /> Trinity: Distributed computation framework based on Ray+RLlib</p>
<p><img alt="air" src="_images/air.png" /> Ethyr: Baseline models and research utility contrib – submit PRs with your own tools!</p>
</div>
<div class="section" id="engineering">
<h2>Engineering<a class="headerlink" href="#engineering" title="Permalink to this headline">¶</a></h2>
<p><strong>Environments that scale to the complexity of the real world</strong></p>
<p><img alt="earth" src="_images/earth.png" /> Blade: Core game environment and extended OpenAI Gym external API</p>
<p><img alt="fire" src="_images/fire.png" /> Embyr: 3D Unity game client for test-time visualization</p>
</div>
</div>
<div class="section" id="icon-quickstart">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Quickstart<a class="headerlink" href="#icon-quickstart" title="Permalink to this headline">¶</a></h1>
<p>The master branch will always contain the latest stable version. Each previous version release is archived in a separate branch. Other branches are for contributors and developers only: they are not bleeding edge builds and may be flammable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Download the Neural MMO environment</span>
<span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">jsuarez5341</span><span class="o">/</span><span class="n">neural</span><span class="o">-</span><span class="n">mmo</span> <span class="o">&amp;&amp;</span> <span class="n">cd</span> <span class="n">neural</span><span class="o">-</span><span class="n">mmo</span>

<span class="c1">#Run the setup script.</span>
<span class="n">python</span> <span class="n">scrips</span><span class="o">/</span><span class="n">setup</span><span class="o">.</span><span class="n">py</span>

<span class="c1">#Headless install (e.g. for remote training)</span>
<span class="n">python</span> <span class="n">scrips</span><span class="o">/</span><span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">NO_SERVER</span>

<span class="c1">#Run the pretrained demo model to test the installation</span>
<span class="n">python</span> <span class="n">Forge</span><span class="o">.</span><span class="n">py</span>

<span class="c1">#Open the client in a separate terminal</span>
<span class="c1">#Server precomputations take ~30 seconds before connecting</span>
<span class="o">./</span><span class="n">client</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
</div>
<div class="section" id="icon-publications">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Publications<a class="headerlink" href="#icon-publications" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="http://ifaamas.org/Proceedings/aamas2020/pdfs/p2020.pdf">Neural MMO v1.3: A Massively Multiagent Game Environmentfor Training and Evaluating Neural Networks</a> (AAMAS, 2020)</p>
<p><a class="reference external" href="https://arxiv.org/abs/2001.12004">Neural MMO v1.3: A Massively Multiagent Game Environment for Training and Evaluating Neural Networks</a> (arXiv, 2020)</p>
<p><a class="reference external" href="https://arxiv.org/abs/1903.00784">Neural MMO: A Massively Multiagent Game Environment for Training and Evaluating Intelligent Agents</a> (arXiv, 2019)</p>
<p><a class="reference external" href="https://github.com/jsuarez5341/neural-mmo">Neural MMO: A Massively Multiagent Game Environment</a> (OpenAI Blog, 2019)</p>
</div>
<div class="section" id="icon-demos">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Demos<a class="headerlink" href="#icon-demos" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://youtu.be/y_f77u9vlLQ">Neural MMO v1.4: A Massively Multiagent Environment for AI Research</a></p>
<p><a class="reference external" href="https://youtu.be/DkHopV1RSxw">Neural MMO v1.3: A Massively Multiagent Game Environment for Training and Evaluating Neural Networks</a></p>
<p><a class="reference external" href="https://youtu.be/tnMquwPjqgI">Neural MMO v1.3 – NeosVR Slides</a></p>
<p><a class="reference external" href="https://s3-us-west-2.amazonaws.com/openai-assets/neural-mmo/neural_mmo_client_demo.mp4">Neural MMO v1.0: A Massively Multiagent Game Environment</a></p>
<p><a class="reference external" href="https://youtu.be/tCo8CPHVtUE">Neural MMO Pre-1.0</a></p>
</div>
<div class="section" id="icon-patch-notes-version-history">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Patch Notes + Version History<a class="headerlink" href="#icon-patch-notes-version-history" title="Permalink to this headline">¶</a></h1>
<p>The <a class="reference external" href="https://github.com/openai/neural-mmo">[OpenAI]</a> repository only hosts v1.0. My personal <a class="reference external" href="https://github.com/jsuarez5341/neural-mmo">[Github]</a> hosts the latest version in <em>master</em> and all previous versions as separate branches. This documentation page is generated from the latest environment release. Feel free to drop in the Discord #support channel if you are having trouble. You can expect fast fixes to Github issues and even faster replies to Discord PMs.</p>
<dl class="simple">
<dt><strong>v1.4:</strong> RLlib Support and Overlays | <a class="reference external" href="https://youtu.be/y_f77u9vlLQ">[Demo]</a></dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Blade: Minor API changes have been made for compatibility with Gym and RLlib</dt><dd><ul>
<li><p>Environment reset method now returns only obs instead of (obs, rewards, dones, infos)</p></li>
<li><p>Environment obs and dones are now both dictionaries keyed by agent ids rather than agent game objects</p></li>
<li><p>The IO modules from v1.3 now delegates batching to the user, e.g. RLlib. As such, several potential sources of error have been removed</p></li>
<li><p>A bug allowing agents to use melee combat from farther away than intended has been fixed</p></li>
<li><p>Minor range and damage balancing has been performed across all three combat styles</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Trinity: This module has been temporarily shelved</dt><dd><ul>
<li><p>Core functionality has been ported to RLlib in collaboration with the developers</p></li>
<li><p>We are working with the RLlib developers to add additional features essential to the long-term scalability of Neural MMO</p></li>
<li><p>The Trinity/Ascend namespace will likely be revived in later infrastructure expansions. For now, the stability of RLlib makes delegating infrastructure pragmatic to enable us to focus on environment development, baseline models, and research</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Ethyr: Proper NN building blocks for complex worlds</dt><dd><ul>
<li><p>Streamlined IO, memory, and attention modules for use in building PyTorch policies</p></li>
<li><p>A high-quality pretrained baseline reproducible at the scale of a single desktop</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Embyr: Overlay shaders for visualizing learned policies</dt><dd><ul>
<li><p>Pressing tilde now brings up an in-game console</p></li>
<li><p>A help menu lists several shader options for visualizing exploration, attention, and learned value functions</p></li>
<li><p>Shaders are rendered over the environment in real-time with partial transparency</p></li>
<li><p>It is no longer necessary to start the client and server in a particular order</p></li>
<li><p>The client no longer needs to be relaunched when the server restarts</p></li>
<li><p>Agents now turn smoothly towards their direction of movement and targeted adversaries</p></li>
<li><p>A graphical bug causing some agent attacks to render at ground level has been fixed</p></li>
<li><p>Moved twistedserver.py into the main neural-mmo repository to better separate client and server</p></li>
<li><p>Confirmed working on Ubuntu, MacOS, and WSL Linux with a Windows client</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>/projekt: Demo code fully rewritten for RLlib</dt><dd><ul>
<li><p>The new demo is much shorter, approximately 400 lines of code</p></li>
<li><p>State-of-the-art Transformer + LSTM based policy trained with distributed PPO</p></li>
<li><p>Batched GPU evaluation for real-time rendering</p></li>
<li><p>Trains in a few hours on a reasonably good desktop (5 rollout worker cores, 1 underutilized GTX 1080Ti GPU)</p></li>
<li><p>To avoid introducing RLlib into the base environment as a hard dependency, we provide a small wrapper class over Realm using RLlib’s environment types</p></li>
<li><p>Migrated from a pip requirements.txt to Poetry for streamlined dependency management</p></li>
<li><p>We have migrated configuration to Google Fire for improved command line argument parsing</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
<dt><strong>v1.3:</strong> Prebuilt IO Libraries | <a class="reference external" href="https://youtu.be/DkHopV1RSxw">[Demo]</a> <a class="reference external" href="https://docs.google.com/presentation/d/1tqm_Do9ph-duqqAlx3r9lI5Nbfb9yUfNEtXk1Qo4zSw/edit?usp=sharing">[Update Slide Deck]</a> <code class="xref download docutils literal notranslate"><span class="pre">[Paper]</span></code></dt><dd><ul class="simple">
<li><p>Blade: We have improved and streamlined the previously unstable and difficult to use IO libraries and migrated them here. The new API provides framework-agnostic IO.inputs and IO.outputs functions that handle all batching, normalization, serialization. Combined with the prebuilt IO networks in Ethyr, these enable seamless interactions with an otherwise complex structured underlying environment interface. We have made corresponding extensions to the OpenAI Gym API to support variable length actions and arguments, as well as to better signal episode boundaries (e.g. agent deaths). The Quickstart guide has been updated to cover this new functionality as part of the core API.</p></li>
<li><p>Trinity: Official support for sharding environment observations across multiple remote servers; performance and logging improvements.</p></li>
<li><p>Ethyr: A Pytorch library for dynamically assembling hierarchical attention networks for processing NMMO IO spaces. We provide a few default attention modules, but users are also free to use their own building blocks – our library can handle any well defined PyTorch network. We have taken care to separate this PyTorch specific functionality from the core IO libraries in Blade: users should find it straightforward to extend our approach to TensorFlow and other deep learning frameworks.</p></li>
<li><p>Embyr: Agents now display additional information overhead, such as when they are immune to attacks or when they have been frozen in place.</p></li>
<li><p>A reasonable 8-population baseline model trained on 12 (old) CPU cores in a day.</p></li>
<li><p>Improved and expanded official documentation</p></li>
<li><p>New tutorials covering distributed computation and the IO API</p></li>
<li><p>The Discord has grown to 80+! Join for active development updates, the quickest support, and community discussions.</p></li>
</ul>
</dd>
<dt><strong>v1.2:</strong> Unity Client and Skilling | <a class="reference external" href="https://docs.google.com/presentation/d/1G9fjYS6j8vZMfzCbB90T6ZmdyixTrQJQwZbs8l9HBVo/edit?usp=sharing">[Update Slide Deck]</a></dt><dd><ul class="simple">
<li><p>Blade: Skilling/professions. This persistent progression system comprises Hunting, Fishing (gathering skills) and Constitution, Melee, Range, Mage (combat skills). Skills are improved through usage: agents that spend a lot of time gathering resources will become able to gather and store more resources at a time. Agents that spend a lot of time fighting will be able to inflict and take more damage. Additional bug fixes and enhancements.</p></li>
<li><p>Trinity: Major new infrastructure API: Ascend – a generalization of Trinity. Whereas v1.1 Trinity implemented cluster, server, and node layer APIs with persistence, synchronous/asynchronous, etc… Ascend implements a single infrastructure “layer” object with all the same features and more. Trinity is still around and functions identically – it has just been reimplemented in ~10 lines of Ascend. Additional bug fixes and features; notable: moved environment out of Trinity.</p></li>
<li><p>Ethyr: Streamlined and simplified IO api. Experience manager classes have been redesigned around v1.2 preferred environment placement, which places the environment server side and only communicates serialized observations and actions – not full rollouts. Expect further changes in the next update – IO is the single most technically complex aspect of this project and has the largest impact on performance.</p></li>
<li><p>Embyr: Focus of this update. Full client rewrite in Unity3D with improved visuals, UI, and controls. The new client makes visualizing policies and tracking down bugs substantially easier. As the environment progresses towards a more complete MMO, development entirely in THREE.js was impractical. This update will also speed up environment development by easing integration into the front end.</p></li>
<li><p>Baseline model is improved but still weak. This is largely a compute issue. I expect the final model to be relatively efficient to train, but I’m currently low on processing power for running parallel experiments. I’ll be regaining cluster access soon.</p></li>
<li><p>Official documentation has been updated accordingly</p></li>
<li><p>20+ people have joined the Discord. I’ve started posting frequent dev updates and thoughts here.</p></li>
</ul>
</dd>
<dt><strong>v1.1:</strong> Infrastructure and API rework, official documentation and Discord | <a class="reference external" href="https://docs.google.com/presentation/d/1EXvluWaaReb2_s5L28dOWqyxf6-fvAbtMcBbaMr-Aow/edit?usp=sharing">[Update Slide Deck]</a></dt><dd><ul class="simple">
<li><p>Blade: Merge Native and VecEnv environment API. New API is closer to Gym</p></li>
<li><p>Trinity: featherweight CPU + GPU infrastructure built on top of Ray and engineered for maximum flexibility. The differences between Rapid style training, tiered MPI gradient aggregation, and even the v1.0 CPU infrastructure are all minor usage details under Trinity.</p></li>
<li><p>Ethyr: New IO api makes it easy to interact with the complex input and output spaces of the environment. Also includes a killer rollout manager with inbuilt batching and serialization for communication across hardware.</p></li>
<li><p>Official github.io documentation and API reference</p></li>
<li><p>Official Discord</p></li>
<li><p>End to end training source. There is also a pretrained model, but it’s just a weak single population foraging baseline around 2.5x of random reward. I’m currently between cluster access – once I get my hands on some better hardware, I’ll retune hyperparameters for the new demo model.</p></li>
</ul>
</dd>
<dt><strong>v1.0:</strong> Initial OpenAI environment release | <a class="reference external" href="https://s3-us-west-2.amazonaws.com/openai-assets/neural-mmo/neural_mmo_client_demo.mp4">[Demo]</a> <a class="reference external" href="https://openai.com/blog/neural-mmo/">[Blog]</a> <a class="reference external" href="https://arxiv.org/pdf/1903.00784.pdf">[Paper]</a></dt><dd><ul class="simple">
<li><p>Blade: Base environment with foraging and combat</p></li>
<li><p>Embyr: THREE.js web client</p></li>
<li><p>Trinity: CPU based distributed training infrastructure</p></li>
<li><p>Ethyr: Contrib library of research utilities</p></li>
<li><p>Basic project-level documentation</p></li>
<li><p>End to end training source and a pretrained model</p></li>
</ul>
</dd>
<dt><strong>v0.x:</strong> Private development | <a class="reference external" href="https://youtu.be/tCo8CPHVtUE">[Neural MMO Pre-1.0]</a></dt><dd><ul class="simple">
<li><p>Personal-scale side project and early prototyping</p></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="icon-rendering-and-overlays">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Rendering and Overlays<a class="headerlink" href="#icon-rendering-and-overlays" title="Permalink to this headline">¶</a></h1>
<p>Embyr is the Neural MMO renderer. It is written in C# using Unity3D and functions much like an MMO game client: rather than directly simulating game logic, it renders the current game state from packets communicated by the Neural MMO server over a Twisted WebSocket. This design cuts out the overhead of running a bulky game engine during training and also enables us to keep the environment in pure Python for faster development. Embyr is maintained in a separate repository for historical reasons as well as because it is large and not required on remote servers during distributed training. Agents advance various foraging and combat skills by collecting food and water and engaging in fights with other agents:</p>
<img alt="_images/v1-4_combat.png" src="_images/v1-4_combat.png" />
<p>To view an agent’s skill levels or follow it with the camera, simply click on it:</p>
<img alt="_images/v1-4_ui.png" src="_images/v1-4_ui.png" />
<p>The client ships with an in-game console (press tilde ~ to toggle) stocked with prebuilt overlays for visualizing various aspects of the learned policy.</p>
<img alt="_images/overlays.svg" src="_images/overlays.svg" /><p>The counts overlay renders a heatmap of agent exploration in real time:</p>
<img alt="_images/v1-4_counts.png" src="_images/v1-4_counts.png" />
<p>The attention overlay renders egocentric heatmaps of each agent’s attention weightings in real time:</p>
<img alt="_images/v1-4_attention.png" src="_images/v1-4_attention.png" />
<p>The values overlay renders a heatmap of the agent’s learned value function in real time:</p>
<img alt="_images/v1-4_values.png" src="_images/v1-4_values.png" />
<p>The globalValues overlay hallucinates an agent on each cell and computes the value function for that agent with no other agents on the map and all resources present. This requires a forward pass for each of the ~3600 tiles in the environment. The overlay is precomputed once during server initialization (~30 seconds) and may be disabled in projekt/config.py for faster startup:</p>
<img alt="_images/v1-4_globalValues.png" src="_images/v1-4_globalValues.png" />
</div>
<div class="section" id="icon-tutorials">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Tutorials<a class="headerlink" href="#icon-tutorials" title="Permalink to this headline">¶</a></h1>
<div class="section" id="training-from-scratch">
<h2>Training from scratch<a class="headerlink" href="#training-from-scratch" title="Permalink to this headline">¶</a></h2>
<p>Next, we will get familiar with the baseline parameters and train a model from scratch. Open up projekt/config.py, which contains all of the training configuration options. You can either edit defaults here or override individual parameters using command line arguments. To train a baseline, simply run:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">Forge</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">LOAD_MODEL</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="o">--</span><span class="n">RENDER</span><span class="o">=</span><span class="bp">False</span>
</pre></div>
</div>
<p>You can reduce batch size if you are running out of memory or disable CUDA if you don’t have a GPU on hand, but performance may suffer. All baseline models train overnight with four i7-9700K CPU cores &#64;3.6 GHz + one GTX 1080Ti at very low utilization and 32 GB of RAM:</p>
<img alt="_images/train.png" src="_images/train.png" />
<p>As a sanity check, your agents should have learned not to run into lava after a few epochs, around 20 average lifetime. The trained baseline models range with 30-40 average lifetime fully trained. However, individual agents may live much longer – we have seen &gt;10000 ticks (~100 minutes real-time). Additionally, higher average lifetime is not always strictly better – the performance of each agent is loosely coupled to the performance of all other agents. Rendering and overlays help resolve discrepancies.</p>
</div>
<div class="section" id="the-io-api">
<h2>The IO API<a class="headerlink" href="#the-io-api" title="Permalink to this headline">¶</a></h2>
<p>OpenAI Gym supports standard definitions for structured, mixed discrete/continuous observation and action (input/output or IO) spaces. However, there are a few issues:</p>
<ol class="arabic simple">
<li><p>OpenAI Gym has a couple of blind spots surrounding dictionary and repeated set observations</p></li>
<li><p>The existence of structured IO spaces does not imply a corresponding neural architecture for processing them</p></li>
</ol>
<p>Neural MMO resolves both of these problems out of the box. We have worked with the RLlib developers to augment OpenAI Gym’s <em>spaces</em> API with two new structure objects, <em>Repeated</em> and <em>FlexDict</em>.</p>
<p>Additionally, we have implemented substantially general procedural generation code that automatically fits attentional PyTorch architectures to the given IO spaces. These will be subject to minor tweaks from update to update but should remain structurally stable from update to update. The high-level concept is to model observations of sets of entities, each of which is a set of attributes:</p>
<img alt="_images/header.svg" src="_images/header.svg" /><p>Entity embeddings are created by attending over attributes, and the observation is flattened to a fixed-length embedding by attenting over entity embeddings. Actions are similarly defined by targeting entity embeddings with attention. The diagram below summarizes this process – see the <a class="reference external" href="https://arxiv.org/abs/2001.12004">[Neural MMO v1.3 white paper]</a> for details</p>
<img alt="_images/io.svg" src="_images/io.svg" /><p>Our Baseline models include an abstract <em>Base</em> model that instantiates our IO modules but defers the hidden network to subclasses:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Base</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
      <span class="o">...</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">Output</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">input</span>  <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">config</span><span class="p">,</span>
            <span class="n">embeddings</span><span class="o">=</span><span class="n">policy</span><span class="o">.</span><span class="n">BiasedInput</span><span class="p">,</span>
            <span class="n">attributes</span><span class="o">=</span><span class="n">policy</span><span class="o">.</span><span class="n">Attention</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">valueF</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">HIDDEN</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

   <span class="k">def</span> <span class="nf">hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">lens</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Implement this method in a subclass&#39;</span><span class="p">)</span>

   <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">lens</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
      <span class="n">entityLookup</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
      <span class="n">hidden</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">entityLookup</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">lens</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">value</span>    <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valueF</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">actions</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">entityLookup</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">actions</span><span class="p">,</span> <span class="n">state</span>
</pre></div>
</div>
<p>Custom models work by defining new subnetworks and overriding the <em>hidden</em> method. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Simple</span><span class="p">(</span><span class="n">Base</span><span class="p">):</span>
   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
      <span class="sd">&#39;&#39;&#39;Simple baseline model with flat subnetworks&#39;&#39;&#39;</span>
      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
      <span class="n">h</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">HIDDEN</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">conv</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">pool</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">fc</span>     <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">h</span><span class="o">*</span><span class="mi">3</span><span class="o">*</span><span class="mi">3</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">proj</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">attend</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">Attention</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>

   <span class="k">def</span> <span class="nf">hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">lens</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
      <span class="c1">#Attentional agent embedding</span>
      <span class="n">agents</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attend</span><span class="p">(</span><span class="n">obs</span><span class="p">[</span><span class="n">Stimulus</span><span class="o">.</span><span class="n">Entity</span><span class="p">])</span>

      <span class="c1">#Convolutional tile embedding</span>
      <span class="n">tiles</span>     <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="n">Stimulus</span><span class="o">.</span><span class="n">Tile</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tiles</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

      <span class="n">w</span>      <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">WINDOW</span>
      <span class="n">batch</span>  <span class="o">=</span> <span class="n">tiles</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">hidden</span> <span class="o">=</span> <span class="n">tiles</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
      <span class="n">tiles</span>  <span class="o">=</span> <span class="n">tiles</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
      <span class="n">tiles</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">tiles</span><span class="p">)</span>
      <span class="n">tiles</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">tiles</span><span class="p">)</span>
      <span class="n">tiles</span>  <span class="o">=</span> <span class="n">tiles</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">tiles</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">tiles</span><span class="p">)</span>

      <span class="n">hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">agents</span><span class="p">,</span> <span class="n">tiles</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">state</span>
</pre></div>
</div>
<p>You can write your own PyTorch models using the same template. Or, if you prefer, you can use our IO subnetworks directly, as is done in our <em>Base</em> class. Neural MMO’s IO spaces themselves are framework agnostic, but if you want to train in e.g. TensorFlow, you will have to write analogous IO networks.</p>
</div>
</div>
<div class="section" id="icon-ideology">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Ideology<a class="headerlink" href="#icon-ideology" title="Permalink to this headline">¶</a></h1>
<p>The dual problem formulation mentioned in the Quickstart guide is core to the guiding ideology of the project. Depending on your own personal conception of where the field is as the moment, this may seem like a practical philosophy, AGI cultism, or anything in between. Regardless, see this <a class="reference external" href="https://docs.google.com/document/d/1_76rYTPtPysSh2_cFFz3Mfso-9VL3_tF5ziaIZ8qmS8/edit?usp=sharing">[Two Pager]</a> for a more thorough overview of the project approach and objective.</p>
<p>The discussion of failure modes below is mostly intended to dissuade skepticism, which thus far I’ve found correlates perfectly with lack of familiarity with MMOs. If you are very familiar with MMOs + current AI research and are still skeptical, please contact me on the Discord – I’d love to hear your views.</p>
<div class="section" id="icon-failure-modes">
<h2><img alt="icon" src="_images/icon_pixel.png" /> Failure Modes<a class="headerlink" href="#icon-failure-modes" title="Permalink to this headline">¶</a></h2>
<p>Evaluation can be somewhat difficult in our setting but is not a major blocker. For smaller experiments, we find population size and resource utilization to be reasonable metrics of success. For larger experiments with sufficient domain randomization, Tournaments (as described in the accompanying paper) allow for cross validation of approaches.</p>
<dl class="simple">
<dt>We are currently aware of three failure cases for the project:</dt><dd><ul class="simple">
<li><p>Computational infeasibility</p></li>
<li><p>“Agents that scale to their environment” is too hard</p></li>
<li><p>“Environments that scale to the real world” is too hard</p></li>
</ul>
</dd>
</dl>
<p>The first failure case is a serious risk, but is shared among all areas of the field. This project is not uniquely compute intensive – in fact, it is one of few environments where it is straightforward to train reasonable policies on a single CPU. If scale is the main issue here, it is likely shared among most if not all other approaches.</p>
<dl class="simple">
<dt>The second problem is probably most familiar to researchers as exploration. Given a cold start, how can agents bootstrap both to better policies and to better exploration strategies? This is a hard problem, but it is unlikely to kill the project because:</dt><dd><ul class="simple">
<li><p>This is independently an important problem that many researchers are already working on already</p></li>
<li><p>The environment of this project is designed collaboratively to assist agents early on in learning, rather than adversarially as a hard benchmark</p></li>
<li><p><a class="reference external" href="https://blog.openai.com/openai-five/">[Recent]</a> <a class="reference external" href="https://blog.openai.com/learning-dexterity/">projects</a> have demonstrated success at scale.</p></li>
</ul>
</dd>
</dl>
<p>The third problem probably appears most likely to many researchers, but least likely to anyone who has spent a significant amount of time in MMOs. Here is a map of the NYC subway:</p>
<img alt="Quest Map" src="_images/quests.png" />
<p><a class="reference external" href="https://www.reddit.com/user/Gamez_X">[Source]</a></p>
<p>Actually, it’s a quest map of Runescape, a particular MMO that our environment is loosely based upon. Each quest is a puzzle in itself, takes anywhere from several minutes to several hours to complete, is part of an interconnected web of prerequisites of other quests, and provides different incentives for completion ranging from equipment to unlockable content to experience in a tightly connected set of skills:</p>
<img alt="Skills" src="_images/skills.png" />
<img alt="Equipment" src="_images/equipment.png" />
<p><a class="reference external" href="https://www.jagex.com/en-GB/">[Source]</a></p>
<p>In a massive open world:</p>
<img alt="GameMap" src="_images/map.png" />
<p><a class="reference external" href="https://www.jagex.com/en-GB/">[Source]</a></p>
<p>The most complex class of games considered to date is MOBAs (Massive Online Battle Arenas, e.g. Dota, Quake CTF), which are round based, take on order of an hour, and are mechanically intensive. Achieving 99 in all skills and acquiring the best gear in Runescape takes, at minimum, several thousand hours. In a tournament setting where attacking other players is allowed everywhere, moment-to-moment gameplay is less important than balancing the risks and rewards of any potential strategy–especially in the presence of hundreds of other players attempting to do the same. There is almost certainly still a complexity gap from MMOs to the real world, but we believe it is much smaller than that in environments currently available.</p>
<p>While our environment is nowhere near the level of complexity of a real MMO yet, it does contain key properties of persistence, population scale, and open-endedness. As agents begin to reach the ceiling of the current environment, we plan on continuing development to raise the ceiling.</p>
</div>
</div>
<div class="section" id="icon-authorship-license-disclaimer">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Authorship, License, Disclaimer<a class="headerlink" href="#icon-authorship-license-disclaimer" title="Permalink to this headline">¶</a></h1>
<p>I, <a class="reference external" href="https://github.com/jsuarez5341">[Joseph Suarez]</a>, am the primary author of Neural MMO. I plan to continue development for at least the duration of my EECS PhD at MIT or until someone convinces me that there is a better way to solve AGI. Everything written in the source and documentation is my own opinion. I do not speak for OpenAI, MIT, Clare, Phillip, Igor, or anyone else involved in the project.</p>
<dl class="simple">
<dt>2020 (spring): v1.3 and v1.4 releases</dt><dd><ul class="simple">
<li><p>Neural MMO v1.3 presented as an Extended Abstract at AAMAS 2020</p></li>
<li><p>Neural MMO v1.3-prerelease presented at a casual seminar in NeosVR</p></li>
</ul>
</dd>
<dt>2019 (fall): Neural MMO development continues at MIT as the main project of my PhD</dt><dd><ul class="simple">
<li><p>I am continuing my role as the primary developer</p></li>
<li><p><strong>Phillip Isola</strong> resumes project oversight as my adviser</p></li>
<li><p>We are beginning to get open source contributions</p></li>
</ul>
</dd>
<dt>2018 (fall): Independent development results in v1.1 and v1.2:</dt><dd><ul class="simple">
<li><p>I ran the project solo. These versions are derivative works and are MIT sublicensed in my name</p></li>
</ul>
</dd>
<dt>2018 (spring): Neural MMO development continues during a 6-month internship at <strong>OpenAI</strong>, culminating in the v1.0 environment (MIT licensed to <strong>OpenAI</strong>) and THREE.js client (MIT licensed to <strong>Joseph Suarez</strong> and <strong>Clare Zhu</strong>) release:</dt><dd><ul class="simple">
<li><p>I continued my role as the primary developer</p></li>
<li><p><strong>Yilun Du</strong> assisted with running experiments and particularly in setting up tournaments for the v1.0 release</p></li>
<li><p><strong>Phillip Isola</strong> and <strong>Igor Mordatch</strong> managed and advised the project</p></li>
<li><p>The v1.0 environment is registered to <strong>OpenAI</strong> and available under the MIT license</p></li>
<li><p>The legacy THREE.js client was developed independently as a collaboration between myself and <strong>Clare Zhu</strong>. It was originally created as follow-up work for the paper and blog post, but we ended up merging it in. This is also the reason that the project is split into two repositories. It is registered to us jointly and is available under the MIT license</p></li>
</ul>
</dd>
<dt>2017 (summer): Neural MMO development begins:</dt><dd><ul class="simple">
<li><p>I started Neural MMO as an independent side project</p></li>
<li><p>I (<strong>Joseph Suarez</strong>) retain ownership of this smaller original code base and game kernel, along with associated ideas. I created these before my affiliations with OpenAI and MIT</p></li>
</ul>
</dd>
<dt>Open source contributors, listed by time since latest contribution. Discord handle have been used for individuals who have not granted explicit permission to display their real names:</dt><dd><ul class="simple">
<li><p><strong>Jack Garbus:</strong> Major contributions to the logging framework, feedback on the documentation and tutorials</p></li>
<li><p><strong>&#64;tdimeola:</strong> Feedback on the documentation and tutorials</p></li>
<li><p><strong>&#64;cehinson:</strong> Mac build of the Unity3D client</p></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="icon-assets">
<h1><img alt="icon" src="_images/icon_pixel.png" /> Assets<a class="headerlink" href="#icon-assets" title="Permalink to this headline">¶</a></h1>
<p>Some assets used in this project belong to <a class="reference external" href="https://www.jagex.com/en-GB/">[Jagex]</a>, the creators of Runescape, such as</p>
<p><img alt="ags" src="_images/ags.png" /> <img alt="earth" src="_images/earth.png" /> <img alt="water" src="_images/water.png" /> <img alt="fire" src="_images/fire.png" /> <img alt="air" src="_images/air.png" /></p>
<p>We currently use them for flavor as an homage to the game that inspired the project. We believe these fall under fair use as a not-for-profit project for the advancement of artificial intelligence research – however, we are more than happy to remove them upon request. We do own the 2D and 3D files for agents, represented by three neurons.</p>
<p><img alt="red" src="_images/red.png" /> <img alt="blue" src="_images/blue.png" /> <img alt="green" src="_images/green.png" /> <img alt="fuchsia" src="_images/fuchsia.png" /> <img alt="orange" src="_images/orange.png" /> <img alt="mint" src="_images/mint.png" /> <img alt="purple" src="_images/purple.png" /> <img alt="spring" src="_images/spring.png" /> <img alt="yellow" src="_images/yellow.png" /> <img alt="cyan" src="_images/cyan.png" /> <img alt="magenta" src="_images/magenta.png" /> <img alt="sky" src="_images/sky.png" /></p>
</div>
<div class="section" id="ags-namesake">
<h1><img alt="ags" src="_images/ags.png" /> Namesake<a class="headerlink" href="#ags-namesake" title="Permalink to this headline">¶</a></h1>
<p>In formal publications, we refer to our project simply as a (the first) “Neural MMO.” Internally and informally, we call it “Projekt: Godsword” (God-Sword). The name comes from two sources: CD Projekt Red, my personal favorite game dev studio, and OldSchool Runescape, which contains an iconic set of weapons called godswords. The latter is a particularly good model for AI environments; the former is more of a soft flavor inspiration.</p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="devguide.html" class="btn btn-neutral float-right" title="Foreword" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Neural MMO v1.4" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Joseph Suarez

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    

  <style>
    :root {
      --foreground: #000000;
      --background: #000e0e;
      --accent:     #005050;
      --text:       #bbbbbb;
      --title:      #00bbbb;
      --monochrome: #bbbbbb;
      --link:       #ffffff;
    }

    body {
      color: var(--text);
    }

    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: var(--background);
    }
    /* Sidebar */
    .wy-nav-side {
      background: var(--foreground);
    }
    .wy-nav-content {
      background: var(--background);
    }
    .wy-nav-content-wrap {
      background: var(--foreground);
    }

    .wy-table-responsive table td, .wy-table-responsive table th {
      /* !important prevents the common CSS stylesheets from
             overriding this as on RTD they are loaded after this stylesheet */
      white-space: normal !important;
    }
       
    .wy-table-responsive {
      overflow: visible !important;
    }

    //This one is the one that does something?
    .row-odd {
      background: #ff0000;
    }

    .row-even {
      background: var(--accent);
    }

    /* Top line */
    hr {
      border-top-color: teal;
      border-top-style: solid;
      border-top-width: 3px;
    }

    /* ****** Begin Tables ****** */

    /*Don't even think about changing this.
    Spent 3 hours pulling this from an rtd bitbucket PR*/ 
    wy-table-odd td, .wy-table-striped tr:nth-child(2n-1) td, .rst-content table.docutils:not(.field-list) tr:nth-child(2n-1) td {
      background-color: var(--foreground);
    }

    wy-table-even td, .wy-table-striped tr:nth-child(2n) td, .rst-content table.docutils:not(.field-list) tr:nth-child(2n) td {
      background-color: var(--background);
    }

    /* Outer table */
    .wy-table-bordered-all, .rst-content table.docutils {
      border: 1px solid #0f0;
        border-top-color: var(--accent);
        border-top-style: solid;
        border-top-width: 1px;
        border-right-color: var(--accent);
        border-right-style: solid;
        border-right-width: 1px;
        border-bottom-color: var(--accent);
        border-bottom-style: solid;
        border-bottom-width: 1px;
        border-left-color: var(--accent);
        border-left-style: solid;
        border-left-width: 1px;
        border-image-outset: 0;
        border-image-repeat: stretch;
        border-image-slice: 100%;
        border-image-source: none;
        border-image-width: 1;
    }

    /* Table header underline */
    .wy-table thead th, .rst-content table.docutils thead th, .rst-content table.field-list thead th {
        font-weight: bold;
        border-bottom-color: rgb(055, 0, 0);
        border-bottom-style: solid;
        border-bottom-width: 0px;
    }

    /* Inner table border */
    .wy-table-bordered-all td, .rst-content table.docutils td {
        border-bottom-color: rgb(255, 0, 0);
        border-bottom-style: solid;
        border-bottom-width: 0px;
        border-left-color: rgb(255, 0, 0);
        border-left-style: solid;
        border-left-width: 0px;
    }
    /* ****** End Tables ****** */

    /* ****** Start selection for left sidebar ****** */
    .wy-menu-vertical li.current{
      background: var(--foreground);
    }

    .wy-menu-vertical li.toctree-l1.current > a{
      background: var(--foreground);
      border-top-color: lime;
      border-top-style: solid;
      border-top-width: 3px;
      border-bottom-color: lime;
      border-bottom-style: solid;
      border-bottom-width: 3px;
      
    }

    .rst-content pre.literal-block, .rst-content div[class^="highlight"] {
      border-top-color: var(--accent);
      border-top-style: solid;
      border-top-width: 1px;
      border-right-color: var(--accent);
      border-right-style: solid;
      border-right-width: 1px;
      border-bottom-color: var(--accent);
      border-bottom-style: solid;
      border-bottom-width: 1px;
      border-left-color: var(--accent);
      border-left-style: solid;
      border-left-width: 1px;
      border-image-outset: 0;
      border-image-repeat: stretch;
      border-image-slice: 100%;
      border-image-source: none;
      border-image-width: 1;
    }

    .wy-menu-vertical li.toctree-l2.current li.toctree-l3 > a {
      display: block;
      background: var(--accent);
      padding: .4045em 4.045em;
    }

    .wy-menu-vertical li.toctree-l2.current > a {
      background: var(--foreground);
      padding: .4045em 2.427em;
    }

    .wy-menu-vertical li.toctree-l3.current li.toctree-l4 > a {
      display: block;
      background: var(--foreground);
      padding: .4045em 5.663em;
    }

    .wy-menu-vertical li.toctree-l2.current li.toctree-l3 > a {
      display: block;
      background: var(--foreground);
      padding: .4045em 4.045em;
    }

    /* ****** End selection for left sidebar ****** */

    /* Bullet(?) blocks */
    .rst-content dl:not(.docutils) dt {
      display: table;
      margin: 6px 0;
      margin-top: 6px;
      font-size: 90%;
      line-height: normal;
      background: var(--foreground);
      color: var(--title);
      border-top: solid 6px var(--accent);
      padding: 6px;
      position: relative;
    }

    /* ****** Start Code Blocks ****** */
    .highlight-python {
      background: var(--accent);
      border: var(--accent);
    }

    .highlight {
      background: var(--foreground);
      color: var(--accent);
    }
    /* ****** End Code Blocks ****** */

    /* Buttons */
    .btn-neutral {
      background-color: var(--accent) !important;
      color: var(--title) !important;
    }

    /* Buttons */
    .btn-neutral:visited {
      background-color: var(--accent) !important;
      color: var(--title) !important;
    }

    .rst-content dl:not(.docutils) dl dt {
      margin-bottom: 6px;
      border-left: solid 0px var(--foreground);
      background: var(--background);
      color: var(--text);
      }

    code, .rst-content tt, .rst-content code {
      background-color: var(--foreground);
      border-top-width: 0px;
      border-bottom-width: 0px;
      border-left-width: 0px;
      border-right-width: 0px;
    }

    .rst-content dl:not(.docutils) dl dt {
      border-left-color: var(--background);
    }

    .rst-content tt, .rst-content tt, .rst-content code {
      color: var(--title);
    }

    .rst-content tt.xref, a .rst-content tt, .rst-content tt.xref, .rst-content code.xref, a .rst-content tt, a .rst-content code {
      color: var(--title);
    }

    .wy-menu-vertical li.toctree-l2 a, .wy-menu-vertical li.toctree-l3 a, .wy-menu-vertical li.toctree-l4 a {
      color: var(--text);
    }

    .wy-menu-vertical li.on a, .wy-menu-vertical li.current > a {
      color: #00ff00;
    }

    .wy-menu-vertical li.current a {
      border-right: solid 1px (--background);
      padding: .4045em 2.427em;
    }

    .wy-menu-vertical header, .wy-menu-vertical p.caption {
       color: var(--title);
       line-height: 32px;
       font-weight: bold;
       text-transform: uppercase;
       font-size: 85%;
       white-space: nowrap;
    }

    footer {
      color: var(--accent);
    }

    p {
      color: var(--text);
    }
    h1 {
      color: var(--title);
    }

    h2 {
      color: var(--accent);
    }

    h3 {
      color: var(--accent);
    }

    h4 {
      color: var(--accent);
    }

    ul {
      list-style: none;
      padding: 0;
      margin: 0;
    }

    li {
      padding-left: 1em; 
      text-indent: -.7em;
    }

    li {
      content: "• ";
      color: var(--title); /* or whatever color you prefer */
      }

    a:link {
      color: var(--link);
    }

    a:visited {
      color: var(--link);
    }

    a:hover {
      color: lime;
    }

    a:active {
      color: lime;
    }


  </style>


</body>
</html>